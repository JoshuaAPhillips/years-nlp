{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BookNLP code for *The Years* ##\n",
    "\n",
    "This is a brain-dump for my Years secret sauce. A bit fancier than a REPL session and you can save stuff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Whatnot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/years-nlp/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cpu\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "from booknlp.booknlp import BookNLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pipeline': 'entity,quote,supersense,event,coref', 'model': 'big'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/years-nlp/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- startup: 8.083 seconds ---\n",
      "--- spacy: 3.510 seconds ---\n",
      "--- entities: 27.417 seconds ---\n",
      "--- quotes: 0.027 seconds ---\n",
      "--- attribution: 28.255 seconds ---\n",
      "--- name coref: 0.039 seconds ---\n",
      "--- coref: 26.632 seconds ---\n",
      "--- TOTAL (excl. startup): 85.967 seconds ---, 21339 words\n",
      "--- spacy: 1.307 seconds ---\n",
      "--- entities: 8.789 seconds ---\n",
      "--- quotes: 0.010 seconds ---\n",
      "--- attribution: 17.049 seconds ---\n",
      "--- name coref: 0.007 seconds ---\n",
      "--- coref: 9.816 seconds ---\n",
      "--- TOTAL (excl. startup): 37.011 seconds ---, 8337 words\n",
      "--- spacy: 1.008 seconds ---\n",
      "--- entities: 8.298 seconds ---\n",
      "--- quotes: 0.008 seconds ---\n",
      "--- attribution: 9.973 seconds ---\n",
      "--- name coref: 0.008 seconds ---\n",
      "--- coref: 8.083 seconds ---\n",
      "--- TOTAL (excl. startup): 27.404 seconds ---, 6218 words\n",
      "--- spacy: 0.511 seconds ---\n",
      "--- entities: 4.492 seconds ---\n",
      "--- quotes: 0.004 seconds ---\n",
      "--- attribution: 2.819 seconds ---\n",
      "--- name coref: 0.005 seconds ---\n",
      "--- coref: 6.846 seconds ---\n",
      "--- TOTAL (excl. startup): 14.696 seconds ---, 3437 words\n",
      "--- spacy: 1.223 seconds ---\n",
      "--- entities: 8.638 seconds ---\n",
      "--- quotes: 0.011 seconds ---\n",
      "--- attribution: 10.978 seconds ---\n",
      "--- name coref: 0.013 seconds ---\n",
      "--- coref: 11.108 seconds ---\n",
      "--- TOTAL (excl. startup): 32.010 seconds ---, 8279 words\n",
      "--- spacy: 2.090 seconds ---\n",
      "--- entities: 14.319 seconds ---\n",
      "--- quotes: 0.015 seconds ---\n",
      "--- attribution: 20.938 seconds ---\n",
      "--- name coref: 0.017 seconds ---\n",
      "--- coref: 15.595 seconds ---\n",
      "--- TOTAL (excl. startup): 53.021 seconds ---, 11810 words\n",
      "--- spacy: 0.799 seconds ---\n",
      "--- entities: 5.263 seconds ---\n",
      "--- quotes: 0.006 seconds ---\n",
      "--- attribution: 10.612 seconds ---\n",
      "--- name coref: 0.008 seconds ---\n",
      "--- coref: 7.830 seconds ---\n",
      "--- TOTAL (excl. startup): 24.540 seconds ---, 5305 words\n",
      "--- spacy: 5.362 seconds ---\n",
      "--- entities: 37.971 seconds ---\n",
      "--- quotes: 0.039 seconds ---\n",
      "--- attribution: 33.217 seconds ---\n",
      "--- name coref: 0.136 seconds ---\n",
      "--- coref: 50.099 seconds ---\n",
      "--- TOTAL (excl. startup): 126.925 seconds ---, 32309 words\n",
      "--- spacy: 1.542 seconds ---\n",
      "--- entities: 10.892 seconds ---\n",
      "--- quotes: 0.011 seconds ---\n",
      "--- attribution: 11.845 seconds ---\n",
      "--- name coref: 0.019 seconds ---\n",
      "--- coref: 14.517 seconds ---\n",
      "--- TOTAL (excl. startup): 38.960 seconds ---, 15269 words\n",
      "--- spacy: 0.132 seconds ---\n",
      "--- entities: 1.015 seconds ---\n",
      "--- quotes: 0.001 seconds ---\n",
      "--- attribution: 0.534 seconds ---\n",
      "--- name coref: 0.001 seconds ---\n",
      "--- coref: 2.071 seconds ---\n",
      "--- TOTAL (excl. startup): 3.764 seconds ---, 1214 words\n",
      "--- spacy: 4.471 seconds ---\n",
      "--- entities: 34.208 seconds ---\n",
      "--- quotes: 0.040 seconds ---\n",
      "--- attribution: 62.462 seconds ---\n",
      "--- name coref: 0.061 seconds ---\n",
      "--- coref: 53.478 seconds ---\n",
      "--- TOTAL (excl. startup): 155.318 seconds ---, 50333 words\n"
     ]
    }
   ],
   "source": [
    "# set model params\n",
    "model_params = {\n",
    "  'pipeline': 'entity,quote,supersense,event,coref',\n",
    "  'model': 'big'\n",
    "}\n",
    "\n",
    "booknlp = BookNLP(\"en\", model_params)\n",
    "\n",
    "# set import/export paths\n",
    "input_path = 'data/'\n",
    "input_files = glob.glob(input_path + 'e1_*.txt')\n",
    "\n",
    "# process files\n",
    "for file in input_files:\n",
    "  idd = os.path.basename(file).split('.')[0]\n",
    "  output_path = 'data/output/' + idd + '/'\n",
    "  booknlp.process(file, output_path, idd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
